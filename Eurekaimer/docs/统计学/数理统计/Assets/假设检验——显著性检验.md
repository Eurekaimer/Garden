# 假设检验——显著性检验

首先先对假设检验进行一个简单的阐述，假设检验(hypothesis testing)最早由K.Pearson于1900年提出，之后由Fisher进行细化发展，最终由Neyman，E.Pearson发展成熟，后又由A.Wald发展为统计决策理论.

参数假设检验主要包含：显著性检验(significance test)和最大功效检验(most powerful test)两部分，本章介绍的就是显著性检验，下一章介绍最大功效检验

## 基本概念

主要是对下面的概念有一个认识：

+ 显著性检验
+ 根据样本推断正确与否的命题称为假设或统计假设
+ 零假设，备择假设
+ 简单假设，复杂假设(根据假设的参数空间决定)
+ 第一类错误，第二类错误(拒真，纳伪)
+ 拒绝域，接收域
+ 势函数，功效函数

关于势函数的定义如下：

$$
\beta_{\psi}(\theta)=P_{\theta}(X\in W),\forall\theta\in\Theta
$$

根据一类错误和二类错误的定义可以知道：

$\theta\in\Theta_{0}$时有犯一类错误的概率为$\beta_{\psi}(\theta)$，那么由于拒绝域是拒绝原假设的，那么对于$\theta\in\Theta_{1}$的情况就有犯二类错误的概率为$1-\beta_{\psi}(\theta)$

注：关于拒绝域的部分有一个思想，类似数学中证明命题，一个例子的成立不能说明整个命题成立，但是否定一个命题只需要举出一个反例，所以在假设检验问题中我们通常关心拒绝域的情况.

并且无法使得一类错误和二类错误都尽可能小，这就提出了一个要求：应该首先控制哪一种错误，根据Neyman提出的原则，我们优先控制第一类错误，使得犯第一类错误的概率不大于$\alpha$，也就是显著性水平的定义

> [!NOTE] 定义 显著性水平
> 对于检验$\psi$和事先给定的$\alpha\in(0,1)$，若是满足$P_{\theta}\left\{ X\in W \right\}\leqslant \alpha,\forall\theta\in\Theta_{0}$，则称$\alpha$为检验$\psi$的显著性水平，也称$\psi$为显著性水平为$\alpha$的检验


我们称只控制检验犯一类错误的概率的检验为显著性检验，那么如何求假设的显著性检验呢，这里先给出基本步骤

一般而言，求取某假设的显著性检验的步骤为：

1. 根据实际问题建立假设，$H_{0}\longleftrightarrow H_{1}$
2. 选取合适的统计量$T(X)$，使当$H_{0}$成立时，$T(X)$的分布已知，并且与参数$\theta$无关，称该分布为$T$的零分布
3. 根据$H_{0},H_{1}$的特点，确定拒绝域的区间形式
4. 对于给定的显著性水平，确定拒绝域$W$
5. 根据样本观测值$x$，计算统计量$T(x)$的值，根据$T(x)$是否属于$W$，做出判断


## 单样本正态总体参数的显著性检验

始终假设$X_{1},X_{2},\dots,X_{n}$为来自正态总体$N(\mu,\sigma^{2})$的$IID$样本

### 单样本正态总体均值的检验

下面是对所有感兴趣的可能情况的一个汇总：

$$
\begin{aligned}
H_{0}:\mu=\mu_{0}\longleftrightarrow H_{1}:\mu\neq \mu_{0}\\
H_{0}:\mu=\mu_{0}\longleftrightarrow H_{1}:\mu< \mu_{0}\\
H_{0}:\mu=\mu_{0}\longleftrightarrow H_{1}:\mu>\mu_{0}\\
H_{0}:\mu \leqslant\mu_{0}\longleftrightarrow H_{1}:\mu>\mu_{0}\\
H_{0}:\mu \geqslant\mu_{0}\longleftrightarrow H_{1}:\mu< \mu_{0}
\end{aligned}
$$

注意$\mu_{0}$是已知的常数，上述假设有单侧、双侧的，简单、复杂的，$\sigma^{2}$的已知与否也会对问题有影响，主要体现在统计量零分布的确定上，因此分类讨论$\sigma^{2}$是否已知

#### $\sigma^{2}=\sigma_{0}^{2}$已知

由于感兴趣的是总体均值$\mu$，挑选样本均值$\overline{X}$构造相关的统计量(良好的点估计)，并且当上述第一个命题的原假设成立时有$\mu=\mu_{0}$，考虑利用$\lvert \overline{X}-\mu_{0} \rvert$的值做一个检验，符合直觉的是，只有当偏离一定程度时才认为原假设不成立，也就是$\lvert \overline{X}-\mu_{0} \rvert>c$时，有理由拒绝原假设$H_{0}$认为$H_{1}$成立

下面这个统计量也称为$U$统计量，检验也叫做$U$检验：

$$
U(X)= \frac{\sqrt{ n }(\overline{X}-\mu_{0})}{\sigma_{0}}
$$

根据上面的分析认为拒绝域为$W=\left\{ x:\lvert U(x) \rvert>c \right\}$，由于是双侧检验加上绝对值，常数$c$需要根据显著性水平确认，当$H_{0}$成立的时候有$U(X)\sim N(0,1)$，那么可以取$c=u_{\frac{\alpha}{2}}$

对于单侧的情况类比可知：$c=u_{\alpha}$

#### $\sigma^{2}$未知

由于$\sigma^{2}$未知考虑利用$S^{2}$替代，这就想到了使用$t$分布

构造$T$统计量$T(X)= \frac{\sqrt{ n }(\overline{X}-\mu_{0})}{S_{n}}\sim t(n-1)$，采用它作为检验统计量，检验称为$t$检验

对于双侧情况容易得到拒绝域应该是$\left\{ x:\lvert T(x) \rvert>t_{\frac{\alpha}{2}}(n-1) \right\}$，单侧情况也是同理的

#### 总结

对于这种分类明显的问题，一表足矣


![t-p test](https://cdn.jsdelivr.net/gh/Eurekaimer/MyIMGs@main/img/u-t%E6%A3%80%E9%AA%8C)



### 单样本正态总体方差的检验

仍然是仿照之前的列出所有情况

$$
\begin{aligned}
H_{0}:\sigma^{2}=\sigma^{2}_{0}\longleftrightarrow H_{1}:\sigma^{2}\neq \sigma^{2}_{0}\\
H_{0}:\sigma^{2}=\sigma^{2}_{0}\longleftrightarrow H_{1}:\sigma^{2}< \sigma^{2}_{0}\\
H_{0}:\sigma^{2}=\sigma^{2}_{0}\longleftrightarrow H_{1}:\sigma^{2}>\sigma^{2}_{0}\\
H_{0}:\sigma^{2}\leqslant\sigma^{2}_{0}\longleftrightarrow H_{1}:\sigma^{2}>\sigma^{2}_{0}\\
H_{0}:\sigma^{2}\geqslant\sigma^{2}_{0}\longleftrightarrow H_{1}:\sigma^{2}< \sigma^{2}_{0}
\end{aligned}
$$

#### $\mu=\mu_{0}$已知


利用$\dfrac{\sum\limits_{i=1}^{n}(X_{i}-\mu_{0})^{2}}{n}$作为一个$\sigma_{0}^{2}$的点估计，当$H_{0}$成立时，$\dfrac{\sum\limits_{i=1}^{n}(X_{i}-\mu_{0})^{2}}{\sigma^{2}}\sim \chi^{2}(n)$，选取检验统计量为$\chi^{2}=\dfrac{\sum\limits_{i=1}^{n}(X_{i}-\mu_{0})^{2}}{\sigma_{0}^{2}}$，在这种情况下拒绝域为$W=\left\{ \chi^{2}<c_{1} \right\}\bigcup \left\{ \chi^{2}>c_{2} \right\}$，其中有$c_{1}<c_{2}$，并且根据显著性水平应有$P_{H_{0}}\left\{ \chi^{2}<c_{1} \right\}+P_{H_{0}}\left\{ \chi^{2}>c_{2} \right\}\leqslant \alpha$


常用的取法是左右拒绝概率各一半显著性水平，也就是$c_{1}=\chi^{2}_{1-\frac{\alpha}{2}}(n),c_{2}=\chi^{2}_{\frac{\alpha}{2}}(n)$

当零假设为$\sigma^{2}\leqslant\sigma_{0}^{2}$，根据备择假设的特点，构造拒绝域的形式为$\left\{ \chi^{2}>c \right\}$那么还应有$P_{H_{0}}\left\{ \chi^{2}>c \right\}\leqslant \alpha$

$$
\begin{aligned}
\alpha&\geqslant P_{H_{0}}\left\{ \chi^{2}>c \right\} \\
&=P_{H_{0}}\left\{ \frac{\sum\limits_{i=1}^{n} (X_{i}-\mu_{0})^{2}}{\sigma_{0}^{2}}>c \right\} \\
&=P_{H_{0}}\left\{ \frac{\sum\limits_{i=1}^{n} (X_{i}-\mu_{0})^{2}}{\sigma^{2}}> \frac{c\sigma_{0}^{2}}{\sigma^{2}} \right\}
\end{aligned}
$$

由于原假设是$\sigma_{0}\geqslant\sigma^{2}$，那么只要$c$满足

$$
\alpha \geqslant P_{H_{0}}\left\{ \frac{\sum\limits_{i=1}^{n} (X_{i}-\mu_{0})^{2}}{\sigma^{2}}> c\right\}
$$


即可，因为$P_{H_{0}}\left\{ \frac{\sum\limits_{i=1}^{n} (X_{i}-\mu_{0})^{2}}{\sigma^{2}}> c\right\}\geqslant P_{H_{0}}\left\{ \frac{\sum\limits_{i=1}^{n} (X_{i}-\mu_{0})^{2}}{\sigma^{2}}> \frac{c\sigma_{0}^{2}}{\sigma^{2}} \right\}$


#### $\mu$未知

仍然是按照$\chi^{2}$统计量的方法，只需要将自由度改为$n-1$即可，统计量为$\chi^{2}=\dfrac{\sum\limits_{i=1}^{n}(X_{i}- \overline{X})^{2}}{\sigma_{0}^{2}}$

注意到这些做法类似枢轴量法的构造方式

## 两样本正态总体参数的显著性检验

### 两样本正态总体均值的显著性检验

$$
\begin{aligned}
H_{0}:\mu_{1}=\mu_{2}\longleftrightarrow H_{1}:\mu_{1}\neq \mu_{2}\\
H_{0}:\mu_{1}\leqslant\mu_{2}\longleftrightarrow H_{1}:\mu_{1}> \mu_{2}\\
H_{0}:\mu_{1}\geqslant\mu_{2}\longleftrightarrow H_{1}:\mu_{1}<\mu_{2}\\
\end{aligned}
$$

如果$\sigma_{1}^{2},\sigma^{2}_{2}$未知，就将均值差的估计称为Behrens-Fisher问题

#### $\sigma_{1}^{2},\sigma_{2}^{2}$均已知

由于$\overline{X},\overline{Y}$是$\mu_{1},\mu_{2}$的良好的点估计，有理由用两样本均值差$\overline{X}-\overline{Y}$来反映$\mu_{1},\mu_{2}$的差，构造$U$统计量为$U=\frac{\overline{X}-\overline{Y}}{\sqrt{ \frac{\sigma_{1}^{2}}{m}+ \frac{\sigma^{2}_{2}}{n} }}\sim N(0,1)$

拒绝域形如$W=\left\{ \lvert U \rvert>c \right\}$，选取$c=u_{\frac{\alpha}{2}}$即可，单侧情况$\mu_{1}\leqslant\mu_{2}$如下

由于$H_{0}$成立时有$\mu_{1}\leqslant\mu_{2}$：

$$
\begin{aligned}
P_{H_{0}}(U>u_{\alpha})&=P_{H_{0}}\left( \frac{\overline{X}-\overline{Y}}{\sqrt{ \frac{\sigma_{1}^{2}}{m}+ \frac{\sigma_{2}^{2}}{n} }}>u_{\alpha} \right)\\
&=P_{H_{0}}\left( \frac{\overline{X}-\overline{Y}-(\mu_{1}-\mu_{2})}{\sqrt{ \frac{\sigma_{1}^{2}}{m}+ \frac{\sigma_{2}^{2}}{n} }}>u_{\alpha} - \frac{\mu_{1}-\mu_{2}}{\sqrt{ \frac{\sigma_{1}^{2}}{m}+ \frac{\sigma_{2}^{2}}{n} }}\right)\\
&\leqslant P_{H_{0}}\left( \frac{\overline{X}-\overline{Y}-(\mu_{1}-\mu_{2})}{\sqrt{ \frac{\sigma_{1}^{2}}{m}+ \frac{\sigma_{2}^{2}}{n} }}>u_{\alpha} \right)=\alpha
\end{aligned}
$$



#### $\sigma_{1}^{2}=\sigma_{2}^{2}=\sigma^{2}$未知

对于相等的原假设，构造$T$统计量如下

$$
T= \frac{(\overline{X}-\overline{Y})\left[ \sigma \sqrt{ \frac{m+n}{mn} } \right] }{\sqrt{ \frac{(m+n-2)S^{*}_{mn}}{\sigma^{2}(m+n-2)} }}=\sqrt{ \frac{mn}{m+n} } \frac{\overline{X}-\overline{Y}}{S^{*}_{mn}}
$$

可以选择拒绝域为：$W=\left\{ \lvert T \rvert>t_{\frac{\alpha}{2}}(m+n-2) \right\}$


#### 一般情况

对于一般情况下两样本正态总体均值的显著性检验问题，给出如下(不加证明)：

1. $m,n$充分大

采用的统计量均为：$U= \frac{\overline{X}-\overline{Y}}{\sqrt{ \frac{S_{1m}^{2}}{m}+ \frac{S_{2n}^{2}}{n} }}$

三大假设的拒绝域为：$\left\{ \lvert U \rvert> u_{\frac{\alpha}{2}} \right\},\left\{ U>u_{\alpha} \right\},\left\{ U<-u_{\alpha} \right\}$

2. $m,n$都不是很大

无法使用大样本近似，$U$统计量近似服从自由度为$r$的$t$分布，对于$r$有如下计算公式：

$$
r= \frac{S_{mn}^{2}}{\frac{S_{1m}^{4}}{m^{2}(m-1)}+ \frac{S_{2n}^{4}}{n^{2}(n-1)}}
$$

三大假设的拒绝域为：$\left\{ \lvert T \rvert> t_{\frac{\alpha}{2}}(r) \right\},\left\{ T>t_{\alpha}(r) \right\},\left\{ T<-t_{\alpha} (r)\right\}$


### 两样本正态总体方差的显著性检验

仍然总结一下感兴趣的情况：

$$
\begin{aligned}
H_{0}:\sigma_{1}^{2}=\sigma^{2}_{2}\longleftrightarrow H_{1}:\sigma^{2}_{1}\neq \sigma^{2}_{2}\\
H_{0}:\sigma^{2}_{1}\leqslant\sigma^{2}_{2}\longleftrightarrow H_{1}:\sigma^{2}_{1}> \sigma^{2}_{2}\\
H_{0}:\sigma^{2}_{1}\geqslant\sigma^{2}_{2}\longleftrightarrow H_{1}:\sigma^{2}_{1}<\sigma^{2}_{2}\\
\end{aligned}
$$

#### $\mu_{1},\mu_{2}$均已知

构造$F$统计量：$F=\frac{S_{1m}^{'2}}{S_{2n}^{'2}}= \frac{\sum\limits_{i=1}^{m}(X_{i}-\mu_{1})^{2}/m}{\sum\limits_{i=1}^{n}(Y_{i}-\mu_{2})^{2}/n}$

#### $\mu_{1},\mu_{2}$均未知

仍然是$F$统计量，只不过需要修改自由度为$(m-1,n-1)$


## 单参数指数型分布族的显著性检验

### 单参数指数型分布族的性质



> [!NOTE] 定理
> 对于单参数指数分布族$f(x,\theta)=c(\theta)\exp(Q(\theta)T(x))h(x)$，$II D$样本$X_{1},X_{2},\dots,X_{n}$，如果$Q(\theta)$是严格增的，$\psi(T(X))$是$T(X)$的非降函数，那么有$E_{\theta}\left[ \psi(T) \right]$也是$\theta$的非降函数

### 单参数指数型分布族的假设检验

### Bernoulli分布的假设检验

这一部分实际就是应用的问题

## 似然比检验

相当重要的一个部分，相当于$MLE$在点估计中的地位

先给出似然比统计量的定义，记号不赘述：

我们考虑的是最一般的假设，也就是$H_{0}:\theta\in\Theta_{0}\longleftrightarrow H_{1}:\theta\in\Theta_{1}=\Theta-\Theta_{0}$

$$
\lambda(X)= \frac{\sup\limits_{\theta\in\Theta_{0}}f(X,\theta)}{\sup\limits_{\theta\in\Theta}f(X,\theta)}
$$

从定义中不难看出，如果该统计量的值很小，就说明在$\Theta_{0}$中的概率小，有理由认为$H_{0}$不成立


那么似然比检验的定义就很自然了：


> [!NOTE] 定义 似然比检验
> 利用$\lambda(X)$作为检验统计量，取拒绝域为$\left\{ \lambda(x)\leqslant c \right\}$，其中临界值$c$满足$P_{\theta}(\lambda(X)\leqslant c)\leqslant \alpha,\forall\theta\in\Theta_{0}$，称其为显著性水平$\alpha$的似然比检验(LRT)

掌握这个思想！

这里面有很多很复杂也很有趣的问题，由于是知识性的笔记在此先不扩展太多.

## $p$值


实际上就是先前显著性检验的一个等价形式(USTC版本的课本将$p$值放在显著性检验的后面，将假设检验全部使用两种方法进行求解，对于$p$值如果陌生可以参考USTC课本)，根据它的定义就可以看出


> [!NOTE] 定义 $p$值
> 对于拒绝域形如$W=\left\{ X:T(X)>c \right\},W=\left\{ X:T(X)<c \right\}$的单侧检验，给定样本的观测值$x^{0}$后即可代入原本检验的检验统计量得出相应的值(在下面的定理中会给出更好的解释)，称$p(x^{0})=\sup\limits_{\theta\in\Theta_{0}}P_{\theta}(T(X)\geqslant T(x^{0}))$或是$p(x^{0})=\sup\limits_{\theta\in\Theta_{0}}P_{\theta}(T(X)\leqslant T(x^{0}))$为此检验的$p$值

定理：样本值$x^{0}$落入显著性水平为$\alpha$的拒绝域$W=\left\{ X:T(X)>c \right\}$的充要条件为此样本的$p$值小于$\alpha$

$p$值的好处在于不需要知道显著性水平，只要大于$p$值的显著性水平$\alpha$，犯一类错误的概率都不超过$\alpha$

而双侧$p$值的形式可以为：

$p(x^{0})=2\min\left\{ \sup\limits_{\theta\in\Theta_{0}}P_{\theta}(T(X)\leqslant T(x^{0})) ,\sup\limits_{\theta\in\Theta_{0}}P_{\theta}(T(X)\geqslant T(x^{0}))\right\}$







